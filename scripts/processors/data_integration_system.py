#!/usr/bin/env python3
"""
ë©€í‹°í”Œë«í¼ ë¶€ë™ì‚° ë°ì´í„° í†µí•© ì‹œìŠ¤í…œ
ë„¤ì´ë²„, ì§ë°©, ë‹¤ë°©, KBë¶€ë™ì‚° ë“±ì˜ ë°ì´í„°ë¥¼ ì •ê·œí™”í•˜ê³  ì¤‘ë³µì„ ì œê±°í•©ë‹ˆë‹¤.
"""

import json
import hashlib
from datetime import datetime
from typing import List, Dict, Set
from loguru import logger
import sys
import os
from dataclasses import dataclass
from difflib import SequenceMatcher

# í•œê¸€ ì¶œë ¥ ì„¤ì •
sys.stdout.reconfigure(encoding='utf-8')


@dataclass
class PropertyData:
    """í‘œì¤€í™”ëœ ë§¤ë¬¼ ë°ì´í„° í´ë˜ìŠ¤"""
    id: str
    platform: str
    type: str
    title: str
    address: str
    price: int
    area: float
    floor: str
    lat: float = None
    lng: float = None
    description: str = ""
    trade_type: str = "ë§¤ë§¤"
    monthly_rent: int = 0
    collected_at: str = ""
    url: str = ""
    raw_data: dict = None


class DataIntegrationSystem:
    """ë°ì´í„° í†µí•© ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.supported_platforms = ['naver', 'zigbang', 'dabang', 'kb']
        self.duplicate_threshold = 0.85  # ì¤‘ë³µ íŒë‹¨ ì„ê³„ê°’
        
    def integrate_all_platforms(self, target_area="ê°•ë‚¨êµ¬ ì‚¼ì„±1ë™", max_per_platform=2000):
        """ëª¨ë“  í”Œë«í¼ ë°ì´í„° í†µí•©"""
        logger.info(f"ğŸ  ë©€í‹°í”Œë«í¼ ë°ì´í„° í†µí•© ì‹œì‘ - {target_area}")
        
        all_properties = []
        platform_stats = {}
        
        # 1. ê° í”Œë«í¼ë³„ ë°ì´í„° ë¡œë“œ
        for platform in self.supported_platforms:
            properties = self._load_platform_data(platform, target_area)
            
            if properties:
                platform_stats[platform] = len(properties)
                all_properties.extend(properties)
                logger.info(f"âœ… {platform}: {len(properties)}ê°œ ë§¤ë¬¼ ë¡œë“œ")
            else:
                platform_stats[platform] = 0
                logger.warning(f"âŒ {platform}: ë°ì´í„° ì—†ìŒ")
        
        logger.info(f"ğŸ“Š ì´ {len(all_properties)}ê°œ ë§¤ë¬¼ ë¡œë“œ ì™„ë£Œ")
        
        # 2. ë°ì´í„° ì •ê·œí™”
        normalized_properties = self._normalize_all_data(all_properties)
        logger.info(f"âœ… ë°ì´í„° ì •ê·œí™” ì™„ë£Œ: {len(normalized_properties)}ê°œ")
        
        # 3. ì¤‘ë³µ ì œê±°
        unique_properties = self._remove_duplicates(normalized_properties)
        logger.info(f"âœ… ì¤‘ë³µ ì œê±° ì™„ë£Œ: {len(unique_properties)}ê°œ (ì œê±°: {len(normalized_properties) - len(unique_properties)}ê°œ)")
        
        # 4. í†µê³„ ë¶„ì„
        statistics = self._analyze_statistics(unique_properties, platform_stats)
        
        # 5. ê²°ê³¼ ë°˜í™˜
        return {
            'area': target_area,
            'integration_time': datetime.now().isoformat(),
            'total_properties': len(unique_properties),
            'platform_stats': platform_stats,
            'statistics': statistics,
            'properties': unique_properties
        }
    
    def _load_platform_data(self, platform, target_area):
        """í”Œë«í¼ë³„ ë°ì´í„° ë¡œë“œ"""
        properties = []
        
        try:
            # í”Œë«í¼ë³„ ìµœì‹  íŒŒì¼ ì°¾ê¸°
            files = [f for f in os.listdir('.') if f.startswith(f'{platform}_') and f.endswith('.json')]
            
            if not files:
                logger.warning(f"No {platform} data files found")
                return properties
            
            # ê°€ì¥ ìµœì‹  íŒŒì¼ ì„ íƒ
            latest_file = max(files, key=lambda x: os.path.getmtime(x))
            
            with open(latest_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                
            if isinstance(data, dict) and 'properties' in data:
                raw_properties = data['properties']
            elif isinstance(data, list):
                raw_properties = data
            else:
                logger.warning(f"Invalid data format in {latest_file}")
                return properties
            
            # í”Œë«í¼ë³„ íŒŒì‹±
            for prop in raw_properties:
                normalized = self._normalize_property(prop, platform)
                if normalized:
                    properties.append(normalized)
                    
            logger.info(f"Loaded {len(properties)} properties from {latest_file}")
            
        except Exception as e:
            logger.error(f"Error loading {platform} data: {e}")
            
        return properties
    
    def _normalize_property(self, prop, platform):
        """ê°œë³„ ë§¤ë¬¼ ë°ì´í„° ì •ê·œí™”"""
        try:
            # í”Œë«í¼ë³„ ë§¤í•‘
            if platform == 'naver':
                return self._normalize_naver(prop)
            elif platform == 'zigbang':
                return self._normalize_zigbang(prop)
            elif platform == 'dabang':
                return self._normalize_dabang(prop)
            elif platform == 'kb':
                return self._normalize_kb(prop)
            else:
                return self._normalize_generic(prop, platform)
                
        except Exception as e:
            logger.debug(f"Error normalizing {platform} property: {e}")
            return None
    
    def _normalize_naver(self, prop):
        """ë„¤ì´ë²„ ë°ì´í„° ì •ê·œí™”"""
        return PropertyData(
            id=f"NAVER_{prop.get('article_id', '')}",
            platform='naver',
            type=prop.get('type', 'ê¸°íƒ€'),
            title=prop.get('title', ''),
            address=prop.get('address', ''),
            price=prop.get('price', 0),
            area=prop.get('area', 0),
            floor=prop.get('floor', ''),
            lat=prop.get('lat'),
            lng=prop.get('lon'),
            description=prop.get('description', ''),
            trade_type=prop.get('trade_type', 'ë§¤ë§¤'),
            collected_at=prop.get('collected_at', ''),
            url=prop.get('naver_link', ''),
            raw_data=prop
        )
    
    def _normalize_zigbang(self, prop):
        """ì§ë°© ë°ì´í„° ì •ê·œí™”"""
        return PropertyData(
            id=prop.get('id', f"ZIGBANG_{hash(str(prop))}"),
            platform='zigbang',
            type=prop.get('type', 'ê¸°íƒ€'),
            title=prop.get('title', ''),
            address=prop.get('address', ''),
            price=prop.get('price', 0),
            area=prop.get('area', 0),
            floor=prop.get('floor', ''),
            lat=prop.get('lat'),
            lng=prop.get('lng'),
            description=prop.get('description', ''),
            monthly_rent=prop.get('monthly_rent', 0),
            collected_at=prop.get('collected_at', ''),
            url=prop.get('url', ''),
            raw_data=prop
        )
    
    def _normalize_dabang(self, prop):
        """ë‹¤ë°© ë°ì´í„° ì •ê·œí™”"""
        return PropertyData(
            id=prop.get('id', f"DABANG_{hash(str(prop))}"),
            platform='dabang',
            type=prop.get('type', 'ê¸°íƒ€'),
            title=prop.get('title', ''),
            address=prop.get('address', ''),
            price=prop.get('price', 0),
            area=prop.get('area', 0),
            floor=prop.get('floor', ''),
            lat=prop.get('lat'),
            lng=prop.get('lng'),
            description=prop.get('description', ''),
            trade_type=prop.get('trade_type', 'ë§¤ë§¤'),
            monthly_rent=prop.get('monthly_rent', 0),
            collected_at=prop.get('collected_at', ''),
            url=prop.get('url', ''),
            raw_data=prop
        )
    
    def _normalize_kb(self, prop):
        """KBë¶€ë™ì‚° ë°ì´í„° ì •ê·œí™”"""
        return PropertyData(
            id=prop.get('id', f"KB_{hash(str(prop))}"),
            platform='kb',
            type=prop.get('type', 'ê¸°íƒ€'),
            title=prop.get('title', ''),
            address=prop.get('address', ''),
            price=prop.get('price', 0),
            area=prop.get('area', 0),
            floor=prop.get('floor', ''),
            description=prop.get('description', ''),
            collected_at=prop.get('collected_at', ''),
            url=prop.get('url', ''),
            raw_data=prop
        )
    
    def _normalize_generic(self, prop, platform):
        """ì¼ë°˜ì ì¸ ë°ì´í„° ì •ê·œí™”"""
        return PropertyData(
            id=prop.get('id', f"{platform.upper()}_{hash(str(prop))}"),
            platform=platform,
            type=prop.get('type', 'ê¸°íƒ€'),
            title=prop.get('title', ''),
            address=prop.get('address', ''),
            price=prop.get('price', 0),
            area=prop.get('area', 0),
            floor=prop.get('floor', ''),
            lat=prop.get('lat'),
            lng=prop.get('lng'),
            description=prop.get('description', ''),
            collected_at=prop.get('collected_at', ''),
            url=prop.get('url', ''),
            raw_data=prop
        )
    
    def _normalize_all_data(self, properties):
        """ëª¨ë“  ë°ì´í„° ì •ê·œí™”"""
        normalized = []
        
        for prop in properties:
            if isinstance(prop, PropertyData):
                normalized.append(prop)
            else:
                # ì´ë¯¸ dict í˜•íƒœë¡œ ì˜¨ ê²½ìš° PropertyDataë¡œ ë³€í™˜
                try:
                    prop_data = PropertyData(**prop)
                    normalized.append(prop_data)
                except Exception as e:
                    logger.debug(f"Error converting to PropertyData: {e}")
                    
        return normalized
    
    def _remove_duplicates(self, properties):
        """ì¤‘ë³µ ë§¤ë¬¼ ì œê±°"""
        unique_properties = []
        seen_hashes = set()
        
        for prop in properties:
            # ì¤‘ë³µ íŒë‹¨ì„ ìœ„í•œ í•´ì‹œ ìƒì„±
            duplicate_hash = self._generate_duplicate_hash(prop)
            
            is_duplicate = False
            
            # ê¸°ì¡´ ë§¤ë¬¼ê³¼ ìœ ì‚¬ë„ ë¹„êµ
            for existing_prop in unique_properties:
                if self._is_duplicate(prop, existing_prop):
                    is_duplicate = True
                    # ë” ì •ë³´ê°€ ë§ì€ ë§¤ë¬¼ë¡œ êµì²´
                    if self._is_better_property(prop, existing_prop):
                        unique_properties.remove(existing_prop)
                        unique_properties.append(prop)
                    break
            
            if not is_duplicate and duplicate_hash not in seen_hashes:
                unique_properties.append(prop)
                seen_hashes.add(duplicate_hash)
        
        return unique_properties
    
    def _generate_duplicate_hash(self, prop):
        """ì¤‘ë³µ íŒë‹¨ìš© í•´ì‹œ ìƒì„±"""
        # ì œëª©, ì£¼ì†Œ, ê°€ê²©, ë©´ì ìœ¼ë¡œ í•´ì‹œ ìƒì„±
        hash_string = f"{prop.title}_{prop.address}_{prop.price}_{prop.area}"
        return hashlib.md5(hash_string.encode()).hexdigest()
    
    def _is_duplicate(self, prop1, prop2):
        """ë‘ ë§¤ë¬¼ì´ ì¤‘ë³µì¸ì§€ íŒë‹¨"""
        # 1. ì œëª© ìœ ì‚¬ë„
        title_similarity = SequenceMatcher(None, prop1.title, prop2.title).ratio()
        
        # 2. ì£¼ì†Œ ìœ ì‚¬ë„
        address_similarity = SequenceMatcher(None, prop1.address, prop2.address).ratio()
        
        # 3. ê°€ê²© ì°¨ì´ (10% ì´ë‚´)
        price_diff = abs(prop1.price - prop2.price) / max(prop1.price, prop2.price, 1)
        price_similarity = 1 - price_diff if price_diff < 0.1 else 0
        
        # 4. ë©´ì  ì°¨ì´ (5% ì´ë‚´)
        area_diff = abs(prop1.area - prop2.area) / max(prop1.area, prop2.area, 1)
        area_similarity = 1 - area_diff if area_diff < 0.05 else 0
        
        # 5. ì¢Œí‘œ ê±°ë¦¬ (ìˆëŠ” ê²½ìš°)
        coord_similarity = 0
        if prop1.lat and prop1.lng and prop2.lat and prop2.lng:
            distance = self._calculate_distance(prop1.lat, prop1.lng, prop2.lat, prop2.lng)
            coord_similarity = 1 if distance < 100 else 0  # 100m ì´ë‚´
        
        # ê°€ì¤‘ í‰ê· ìœ¼ë¡œ ìµœì¢… ìœ ì‚¬ë„ ê³„ì‚°
        weights = [0.3, 0.3, 0.2, 0.1, 0.1]
        similarities = [title_similarity, address_similarity, price_similarity, area_similarity, coord_similarity]
        
        total_similarity = sum(w * s for w, s in zip(weights, similarities))
        
        return total_similarity >= self.duplicate_threshold
    
    def _calculate_distance(self, lat1, lng1, lat2, lng2):
        """ë‘ ì¢Œí‘œ ê°„ ê±°ë¦¬ ê³„ì‚° (ë¯¸í„°)"""
        import math
        
        R = 6371000  # ì§€êµ¬ ë°˜ì§€ë¦„ (ë¯¸í„°)
        
        lat1_rad = math.radians(lat1)
        lat2_rad = math.radians(lat2)
        delta_lat = math.radians(lat2 - lat1)
        delta_lng = math.radians(lng2 - lng1)
        
        a = (math.sin(delta_lat / 2) ** 2 +
             math.cos(lat1_rad) * math.cos(lat2_rad) * math.sin(delta_lng / 2) ** 2)
        
        c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))
        
        return R * c
    
    def _is_better_property(self, prop1, prop2):
        """ì–´ëŠ ë§¤ë¬¼ì´ ë” ì •ë³´ê°€ í’ë¶€í•œì§€ íŒë‹¨"""
        score1 = self._calculate_info_score(prop1)
        score2 = self._calculate_info_score(prop2)
        
        return score1 > score2
    
    def _calculate_info_score(self, prop):
        """ë§¤ë¬¼ ì •ë³´ ì ìˆ˜ ê³„ì‚°"""
        score = 0
        
        if prop.title: score += 1
        if prop.address: score += 1
        if prop.price > 0: score += 1
        if prop.area > 0: score += 1
        if prop.lat and prop.lng: score += 2
        if prop.description: score += 1
        if prop.url: score += 1
        
        return score
    
    def _analyze_statistics(self, properties, platform_stats):
        """í†µê³„ ë¶„ì„"""
        stats = {
            'by_platform': platform_stats,
            'by_type': {},
            'by_trade': {},
            'by_price_range': {},
            'by_area_range': {},
            'price_stats': {},
            'area_stats': {}
        }
        
        if not properties:
            return stats
        
        # íƒ€ì…ë³„ í†µê³„
        for prop in properties:
            prop_type = prop.type
            trade_type = prop.trade_type
            
            stats['by_type'][prop_type] = stats['by_type'].get(prop_type, 0) + 1
            stats['by_trade'][trade_type] = stats['by_trade'].get(trade_type, 0) + 1
        
        # ê°€ê²© ë²”ìœ„ë³„ í†µê³„
        for prop in properties:
            price = prop.price
            if price <= 10000:
                range_key = "1ì–µ ì´í•˜"
            elif price <= 50000:
                range_key = "1ì–µ-5ì–µ"
            elif price <= 100000:
                range_key = "5ì–µ-10ì–µ"
            else:
                range_key = "10ì–µ ì´ˆê³¼"
                
            stats['by_price_range'][range_key] = stats['by_price_range'].get(range_key, 0) + 1
        
        # ë©´ì  ë²”ìœ„ë³„ í†µê³„
        for prop in properties:
            area = prop.area
            if area <= 40:
                range_key = "40ã¡ ì´í•˜"
            elif area <= 60:
                range_key = "40-60ã¡"
            elif area <= 85:
                range_key = "60-85ã¡"
            else:
                range_key = "85ã¡ ì´ˆê³¼"
                
            stats['by_area_range'][range_key] = stats['by_area_range'].get(range_key, 0) + 1
        
        # ê°€ê²©/ë©´ì  í†µê³„
        prices = [p.price for p in properties if p.price > 0]
        areas = [p.area for p in properties if p.area > 0]
        
        if prices:
            stats['price_stats'] = {
                'min': min(prices),
                'max': max(prices),
                'avg': sum(prices) / len(prices),
                'median': sorted(prices)[len(prices) // 2]
            }
        
        if areas:
            stats['area_stats'] = {
                'min': min(areas),
                'max': max(areas),
                'avg': sum(areas) / len(areas),
                'median': sorted(areas)[len(areas) // 2]
            }
        
        return stats
    
    def save_integrated_data(self, integrated_data, filename_prefix="integrated_samsung1dong"):
        """í†µí•© ë°ì´í„° ì €ì¥"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # JSON íŒŒì¼ ì €ì¥
        json_filename = f"{filename_prefix}_{timestamp}.json"
        
        # PropertyData ê°ì²´ë¥¼ dictë¡œ ë³€í™˜
        serializable_data = integrated_data.copy()
        serializable_data['properties'] = [
            {
                'id': prop.id,
                'platform': prop.platform,
                'type': prop.type,
                'title': prop.title,
                'address': prop.address,
                'price': prop.price,
                'area': prop.area,
                'floor': prop.floor,
                'lat': prop.lat,
                'lng': prop.lng,
                'description': prop.description,
                'trade_type': prop.trade_type,
                'monthly_rent': prop.monthly_rent,
                'collected_at': prop.collected_at,
                'url': prop.url
            }
            for prop in integrated_data['properties']
        ]
        
        with open(json_filename, 'w', encoding='utf-8') as f:
            json.dump(serializable_data, f, ensure_ascii=False, indent=2)
        
        logger.info(f"âœ… í†µí•© ë°ì´í„° ì €ì¥ ì™„ë£Œ: {json_filename}")
        
        return json_filename


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    logger.info("ğŸ  ë©€í‹°í”Œë«í¼ ë¶€ë™ì‚° ë°ì´í„° í†µí•© ì‹œìŠ¤í…œ ì‹œì‘")
    
    # í†µí•© ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    integrator = DataIntegrationSystem()
    
    # ëª¨ë“  í”Œë«í¼ ë°ì´í„° í†µí•©
    integrated_data = integrator.integrate_all_platforms()
    
    # ê²°ê³¼ ì¶œë ¥
    logger.info("ğŸ“Š í†µí•© ê²°ê³¼:")
    logger.info(f"ì´ ë§¤ë¬¼ ìˆ˜: {integrated_data['total_properties']:,}ê°œ")
    logger.info(f"í”Œë«í¼ë³„ í†µê³„: {integrated_data['platform_stats']}")
    logger.info(f"íƒ€ì…ë³„ í†µê³„: {integrated_data['statistics']['by_type']}")
    
    # íŒŒì¼ ì €ì¥
    filename = integrator.save_integrated_data(integrated_data)
    
    # ëª©í‘œ ë‹¬ì„± í™•ì¸
    total = integrated_data['total_properties']
    target = 8000
    
    if total >= target:
        logger.info(f"ğŸ‰ ëª©í‘œ ë‹¬ì„±! {total:,}ê°œ >= {target:,}ê°œ")
    else:
        logger.warning(f"âŒ ëª©í‘œ ë¯¸ë‹¬ì„±: {total:,}ê°œ < {target:,}ê°œ (ë¶€ì¡±: {target - total:,}ê°œ)")
    
    return integrated_data


if __name__ == "__main__":
    main()